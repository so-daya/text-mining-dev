# ui_components.py
import streamlit as st
import pandas as pd
import re
import os # os.path.basename ã®ãŸã‚ (ãŸã ã—ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³å‰Šé™¤ã«ã‚ˆã‚Šä¸è¦ã«ãªã‚‹å¯èƒ½æ€§ã‚ã‚Š)

from config import (DEFAULT_TARGET_POS, GENERAL_STOP_WORDS,
                    SESSION_KEY_KWIC_KEYWORD, SESSION_KEY_KWIC_MODE_IDX, SESSION_KEY_KWIC_WINDOW_VAL,
                    SESSION_KEY_ACTIVE_TAB, TAB_NAME_KWIC) # KWICã‚¿ãƒ–ã®on_changeã§ä½¿ç”¨
from text_analyzer import (generate_word_report, generate_wordcloud_image,
                           generate_cooccurrence_network_html, perform_kwic_search)

def show_sidebar_options():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³UIã‚’è¡¨ç¤ºã—ã€é¸æŠã•ã‚ŒãŸå€¤ã‚’è¾æ›¸ã§è¿”ã™ã€‚"""
    st.sidebar.header("âš™ï¸ åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    st.sidebar.markdown("**å“è©é¸æŠ (å„åˆ†æå…±é€š)**")
    
    pos_options = ['åè©', 'å‹•è©', 'å½¢å®¹è©', 'å‰¯è©', 'æ„Ÿå‹•è©', 'é€£ä½“è©']
    report_target_pos = st.sidebar.multiselect("å˜èªãƒ¬ãƒãƒ¼ãƒˆ: å¯¾è±¡å“è©", pos_options, default=DEFAULT_TARGET_POS)
    wc_target_pos = st.sidebar.multiselect("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰: å¯¾è±¡å“è©", pos_options, default=DEFAULT_TARGET_POS)
    net_target_pos = st.sidebar.multiselect("å…±èµ·Net: å¯¾è±¡å“è©", pos_options, default=DEFAULT_TARGET_POS)

    st.sidebar.markdown("**ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰è¨­å®š**")
    
    unique_default_stopwords = sorted(list(set(word.strip().lower() for word in GENERAL_STOP_WORDS if word.strip())))
    default_stopwords_str = ", ".join(unique_default_stopwords)
    
    custom_stopwords_input = st.sidebar.text_area(
        "å…±é€šã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ (åŸå½¢ã‚’ã‚«ãƒ³ãƒã‚„æ”¹è¡ŒåŒºåˆ‡ã‚Šã§å…¥åŠ›):",
        value=default_stopwords_str,
        help="ã“ã“ã«å…¥åŠ›ã—ãŸå˜èªï¼ˆåŸå½¢ï¼‰ãŒã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã¨ã—ã¦å‡¦ç†ã•ã‚Œã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
    )
    
    final_stop_words = set()
    if custom_stopwords_input.strip():
        current_stopwords_list = [word.strip().lower() for word in re.split(r'[,\n]', custom_stopwords_input) if word.strip()]
        final_stop_words.update(current_stopwords_list)
        
    st.sidebar.caption(f"é©ç”¨ã•ã‚Œã‚‹ç·ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰æ•°: {len(final_stop_words)}")

    st.sidebar.markdown("---")
    st.sidebar.markdown("**å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©³ç´°è¨­å®š**")
    node_min_freq = st.sidebar.slider("ãƒãƒ¼ãƒ‰æœ€ä½å‡ºç¾æ•°:", 1, 20, 2, key="net_node_freq_slider_main")
    edge_min_freq = st.sidebar.slider("ã‚¨ãƒƒã‚¸æœ€ä½å…±èµ·æ•°:", 1, 10, 2, key="net_edge_freq_slider_main")

    return {
        "report_pos": report_target_pos,
        "wc_pos": wc_target_pos,
        "net_pos": net_target_pos,
        "stop_words": final_stop_words,
        "node_min_freq": node_min_freq,
        "edge_min_freq": edge_min_freq
    }

def show_report_tab(morphemes_data, target_pos, stop_words):
    """ã€Œå˜èªå‡ºç¾ãƒ¬ãƒãƒ¼ãƒˆã€ã‚¿ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    st.subheader("ğŸ“Š å˜èªå‡ºç¾ãƒ¬ãƒãƒ¼ãƒˆ")
    with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­..."):
        df_report, total_morphs, total_target_morphs = generate_word_report(
            tuple(morphemes_data), tuple(target_pos), tuple(stop_words) # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãŸã‚ã‚¿ãƒ—ãƒ«åŒ–
        )
        st.caption(f"ç·å½¢æ…‹ç´ æ•°: {total_morphs} | ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡ã®ç•°ãªã‚Šèªæ•°: {len(df_report)} | ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡ã®å»¶ã¹èªæ•°: {total_target_morphs}")
        if not df_report.empty:
            st.dataframe(df_report.style.bar(subset=['å‡ºç¾æ•°'], align='left', color='#90EE90')
                                     .format({'å‡ºç¾é »åº¦ (%)': "{:.3f}%"}))
        else:
            st.info("ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡ã®å˜èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

def show_wordcloud_tab(morphemes_data, font_path, target_pos, stop_words):
    """ã€Œãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã€ã‚¿ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    st.subheader("â˜ï¸ ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
    if font_path:
        with st.spinner("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆä¸­..."):
            fig_wc = generate_wordcloud_image(
                tuple(morphemes_data), font_path, tuple(target_pos), tuple(stop_words)
            )
            if fig_wc:
                st.pyplot(fig_wc)
        # st.caption(f"ä½¿ç”¨ãƒ•ã‚©ãƒ³ãƒˆ: {os.path.basename(font_path) if font_path else 'æœªè¨­å®š'}") # â˜…å‰Šé™¤
    else:
        st.error("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®æº–å‚™ãŒã§ãã¦ã„ã¾ã›ã‚“ã€‚ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

def show_network_tab(morphemes_data, text_input, tagger_dummy, font_path, font_name, target_pos, stop_words, node_min_freq, edge_min_freq):
    """ã€Œå…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ã‚¿ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    st.subheader("ğŸ•¸ï¸ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
    if font_path and font_name:
        with st.spinner("å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç”Ÿæˆä¸­..."):
            html_cooc = generate_cooccurrence_network_html(
                tuple(morphemes_data), text_input, tagger_dummy,
                font_path, font_name, tuple(target_pos), tuple(stop_words),
                node_min_freq, edge_min_freq
            )
            if html_cooc:
                st.components.v1.html(html_cooc, height=750, scrolling=True)
        # st.caption(f"ä½¿ç”¨ãƒ•ã‚©ãƒ³ãƒˆ (ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«): {font_name if font_name else 'æœªè¨­å®š'}") # â˜…å‰Šé™¤
    else:
        st.error("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®æº–å‚™ãŒã§ãã¦ã„ã¾ã›ã‚“ã€‚å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

def show_kwic_tab(morphemes_data):
    """ã€ŒKWICæ¤œç´¢ã€ã‚¿ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    st.subheader("ğŸ” KWICæ¤œç´¢ (æ–‡è„ˆä»˜ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢)")

    # --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã®å®šç¾© (KWICã‚¿ãƒ–ã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ä¿ã¤ãŸã‚) ---
    def update_kwic_keyword_and_active_tab():
        st.session_state[SESSION_KEY_KWIC_KEYWORD] = st.session_state.kwic_keyword_input_field_tab
        st.session_state[SESSION_KEY_ACTIVE_TAB] = TAB_NAME_KWIC

    def update_kwic_mode_and_active_tab():
        kwic_search_options = ("åŸå½¢ä¸€è‡´", "è¡¨å±¤å½¢ä¸€è‡´")
        st.session_state[SESSION_KEY_KWIC_MODE_IDX] = kwic_search_options.index(st.session_state.kwic_mode_radio_field_tab)
        st.session_state[SESSION_KEY_ACTIVE_TAB] = TAB_NAME_KWIC

    def update_kwic_window_and_active_tab():
        st.session_state[SESSION_KEY_KWIC_WINDOW_VAL] = st.session_state.kwic_window_slider_field_tab
        st.session_state[SESSION_KEY_ACTIVE_TAB] = TAB_NAME_KWIC

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– (ã“ã®ã‚¿ãƒ–å°‚ç”¨ã®ã‚­ãƒ¼) ---
    if SESSION_KEY_KWIC_KEYWORD not in st.session_state:
        st.session_state[SESSION_KEY_KWIC_KEYWORD] = ""
    if SESSION_KEY_KWIC_MODE_IDX not in st.session_state:
        st.session_state[SESSION_KEY_KWIC_MODE_IDX] = 0 # "åŸå½¢ä¸€è‡´"
    if SESSION_KEY_KWIC_WINDOW_VAL not in st.session_state:
        st.session_state[SESSION_KEY_KWIC_WINDOW_VAL] = 5

    # --- UIã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ ---
    kwic_keyword_input_val = st.text_input(
        "KWICæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:",
        value=st.session_state[SESSION_KEY_KWIC_KEYWORD],
        placeholder="æ¤œç´¢ã—ãŸã„å˜èª(åŸå½¢æ¨å¥¨)...",
        key="kwic_keyword_input_field_tab",
        on_change=update_kwic_keyword_and_active_tab
    )

    kwic_search_options_list = ("åŸå½¢ä¸€è‡´", "è¡¨å±¤å½¢ä¸€è‡´")
    st.radio( # è¿”ã‚Šå€¤ã¯ä½¿ã‚ãªã„ã®ã§ä»£å…¥ã—ãªã„
        "KWICæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰:", kwic_search_options_list,
        index=st.session_state[SESSION_KEY_KWIC_MODE_IDX],
        key="kwic_mode_radio_field_tab",
        on_change=update_kwic_mode_and_active_tab,
        horizontal=True
    )

    st.slider( # è¿”ã‚Šå€¤ã¯ä½¿ã‚ãªã„ã®ã§ä»£å…¥ã—ãªã„
        "KWICè¡¨ç¤ºæ–‡è„ˆã®å½¢æ…‹ç´ æ•° (å‰å¾Œå„):", 1, 15,
        value=st.session_state[SESSION_KEY_KWIC_WINDOW_VAL], # value ã§ç¾åœ¨ã®å€¤ã‚’è¡¨ç¤º
        key="kwic_window_slider_field_tab",
        on_change=update_kwic_window_and_active_tab
    )

    # --- æ¤œç´¢å®Ÿè¡Œã¨çµæœè¡¨ç¤º ---
    # æ¤œç´¢ã«ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®ç¾åœ¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    current_kwic_keyword = st.session_state[SESSION_KEY_KWIC_KEYWORD]
    if current_kwic_keyword.strip():
        search_key_type_for_kwic_val = 'åŸå½¢' if st.session_state[SESSION_KEY_KWIC_MODE_IDX] == 0 else 'è¡¨å±¤å½¢'
        kw_to_search = current_kwic_keyword.strip()
        current_kwic_window_val = st.session_state[SESSION_KEY_KWIC_WINDOW_VAL]

        with st.spinner(f"ã€Œ{kw_to_search}ã€ã‚’æ¤œç´¢ä¸­..."):
            results_kwic_list_data = perform_kwic_search(
                tuple(morphemes_data), kw_to_search, search_key_type_for_kwic_val, current_kwic_window_val
            )
        if results_kwic_list_data:
            st.write(f"ã€Œ{kw_to_search}ã€ã®æ¤œç´¢çµæœ ({len(results_kwic_list_data)}ä»¶):")
            df_kwic_to_display_final = pd.DataFrame(results_kwic_list_data)
            st.dataframe(df_kwic_to_display_final)
        else:
            st.info(f"ã€Œ{kw_to_search}ã€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆç¾åœ¨ã®æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã«ãŠã„ã¦ï¼‰ã€‚")
